{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009e76ff-c751-40ca-a506-e9f3cf36b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import yfinance as yf\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime as dt\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1f92e4-77ca-4ac9-a754-768a8f92061d",
   "metadata": {},
   "source": [
    "Analyze Sentiment Scores with GPT 5 Nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef9f1da-0c7a-45fa-a444-4f4c9e64bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_calls = pd.read_csv('all_calls.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd23a7e2-7e6b-4f29-b5fd-127a3dcdd12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sp_universe = pd.read_csv('spx2015_top3sectors_50.csv')\n",
    "custom_sp_universe = custom_sp_universe.Ticker.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee905eed-906b-4a24-98c1-f9e36362019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_calls = all_calls[all_calls.ticker.isin(custom_sp_universe)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de6778f8-f960-4edc-9ae7-91c9d9c56790",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "MODEL = \"gpt-5-nano\"\n",
    "MAX_OUTPUT_TOKENS = 500\n",
    "CHAR_CAP = 80_000\n",
    "CHECKPOINT_PATH = \"all_calls_progress.csv\"\n",
    "SAVE_EVERY = 50\n",
    "\n",
    "PROMPT_HEADER = \"\"\"I will provide the transcript of an earnings call. Your job is to analyze the text only based on what is actually present in the transcript. For each of the following categories, assign a score between -1 and 1:\n",
    "\n",
    "forward_looking_sentiment: How positive or negative is the company’s outlook or projections for the future?\n",
    "management_confidence: How confident does management appear about business performance and strategy?\n",
    "risk_and_uncertainty: How much concern, risk, or uncertainty is conveyed (higher = more risk)?\n",
    "qa_sentiment: How positive or negative is the tone during the Q&A section with analysts?\n",
    "opening_sentiment: How positive or negative is the opening section or prepared remarks?\n",
    "financial_performance_sentiment: Based solely on what is said in the transcript, how positively is past financial performance portrayed?\n",
    "macroeconomic_reference_sentiment: If there are references to broader macroeconomic conditions, how optimistic or pessimistic are those?\n",
    "\n",
    "If a category is not addressed clearly in the transcript, return exactly 0 for that category.\n",
    "\n",
    "Use the following format for your output:\n",
    "{\n",
    "  \"forward_looking_sentiment\": ___,\n",
    "  \"management_confidence\": ___,\n",
    "  \"risk_and_uncertainty\": ___,\n",
    "  \"qa_sentiment\": ___,\n",
    "  \"opening_sentiment\": ___,\n",
    "  \"financial_performance_sentiment\": ___,\n",
    "  \"macroeconomic_reference_sentiment\": ___\n",
    "}\n",
    "Do not include any text or explanation—only return the JSON object. Do not guess or infer information that is not directly stated in the transcript.\n",
    "\n",
    "Transcript:\"\"\"\n",
    "\n",
    "def build_prompt(transcript: str) -> str:\n",
    "    return f\"{PROMPT_HEADER}\\n{(transcript or '')[:CHAR_CAP]}\"\n",
    "\n",
    "def call_gpt_nano(prompt: str, max_retries: int = 5):\n",
    "    delays = [1, 2, 5, 10, 20]\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            resp = client.responses.create(\n",
    "                model=MODEL,\n",
    "                input=prompt,\n",
    "                max_output_tokens=MAX_OUTPUT_TOKENS,\n",
    "                reasoning={\"effort\": \"low\"},\n",
    "                text={\"format\": {\"type\": \"json_object\"}, \"verbosity\": \"low\"},\n",
    "            )\n",
    "            return resp.output_text.strip()\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                return None\n",
    "            time.sleep(delays[min(attempt, len(delays)-1)])\n",
    "\n",
    "def safe_json_load(s: str):\n",
    "    if not s: return {}\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except json.JSONDecodeError:\n",
    "        s2 = s.strip().strip(\"`\").replace(\"```json\",\"\").replace(\"```\",\"\").strip()\n",
    "        try: return json.loads(s2)\n",
    "        except: return {}\n",
    "\n",
    "# ---- load dataframe ----\n",
    "# assume you already loaded all_calls with column earnings_call_raw_text\n",
    "# all_calls = pd.read_csv(\"all_calls.csv\")\n",
    "\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    saved = pd.read_csv(CHECKPOINT_PATH)\n",
    "    for col in saved.columns:\n",
    "        if col not in all_calls.columns:\n",
    "            all_calls[col] = saved[col]\n",
    "\n",
    "if \"analysis_json\" not in all_calls.columns:\n",
    "    all_calls[\"analysis_json\"] = None\n",
    "\n",
    "result_cols = [\n",
    "    \"forward_looking_sentiment\",\n",
    "    \"management_confidence\",\n",
    "    \"risk_and_uncertainty\",\n",
    "    \"qa_sentiment\",\n",
    "    \"opening_sentiment\",\n",
    "    \"financial_performance_sentiment\",\n",
    "    \"macroeconomic_reference_sentiment\",\n",
    "]\n",
    "for c in result_cols:\n",
    "    if c not in all_calls.columns:\n",
    "        all_calls[c] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb99203-e4ae-4904-b9d1-2bb78838d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit api calls and log progress\n",
    "processed_since_save = 0\n",
    "for i, row in all_calls.iterrows():\n",
    "    if pd.notna(row.get(\"analysis_json\")) and str(row[\"analysis_json\"]).strip():\n",
    "        continue\n",
    "\n",
    "    prompt = build_prompt(row[\"earnings_call_raw_text\"])\n",
    "    txt = call_gpt_nano(prompt)\n",
    "    all_calls.at[i, \"analysis_json\"] = txt\n",
    "\n",
    "    parsed = safe_json_load(txt)\n",
    "    for c in result_cols:\n",
    "        all_calls.at[i, c] = parsed.get(c, None)\n",
    "\n",
    "    processed_since_save += 1\n",
    "    if processed_since_save >= SAVE_EVERY:\n",
    "        all_calls.to_csv(CHECKPOINT_PATH, index=False)\n",
    "        processed_since_save = 0\n",
    "\n",
    "# final save\n",
    "all_calls.to_csv(CHECKPOINT_PATH, index=False)\n",
    "print(\"Done. Checkpoint saved to\", CHECKPOINT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-earnings-call",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
